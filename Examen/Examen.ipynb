{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La historia jamás contada: Los Anunnaki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://www.sitchinstudies.com/uploads/1/4/3/3/14331428/editor/sumerian-artifact.jpg?1522148947\" width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una lástima que las clases de historia de hoy en día no se dediquen a motivar interés sobre los enigmas que nos faltan por resolver. La historia juega un papel clave en el desarrollo humano: _aquél que no conoce su historia está condenado a repetirla_. No sólo esto, pero hay cosas que por intereses políticos o económicos no se revelan o se disfrazan ante la población común y corriente como nosotros.\n",
    "\n",
    "Son varios los agujeros que hay en las historias sobre las sociedades anteriores a Cristo, los egipcios, los sumerios e incluso los mayas. Dudas sobre su verdadero entendimiento de la naturaleza y sus leyes, las fuentes mismas de esta información. Es así que hago referencia a los sumerios: la primer civilización _documentada_.\n",
    "\n",
    "La _tableta_ que se encuentra arriba es un pequeño enigma: a la izquierda, tenemos a dos sumerios, y a la derecha una representación de un **Anunnaki**. Los sumerios nunca se dieron crédito por sus conocimientos de agricultura, de astronomía, ni de ingeniería. Todo lo atribuyeron a unos seres _supremos_ denominados Anunnaki. A los medios _mainstream_ les gusta decir que estas son sólo metáforas para hablar de sus deidades, osea, personajes de ficción. Pero hay algunas cuantas inconsistencias con este relato, por ejemplo esta tableta de unos 6000 años de antigüedad en donde se ve un pequeño sistema solar, un aparente conocimiento de una teoría Heliocéntrica (además de una coincidencia en el número de cuerpos celestes que orbitan), poco probable que sea una coincidencia.\n",
    "\n",
    "Es a partir de aquí que ustedes tienen que _conectar los puntos_ para encontrar algunas piezas apócrifas de este rompecabezas.\n",
    "\n",
    "## Sección 1: Desempolvando y limpiando los fósiles y reliquias\n",
    "\n",
    "Aquellas anécdotas que han pasado de libro en libro, que casi no se enseñan en la educación básica de país alguno, han podido ser entendidas por analistas lingüistas, que se dieron a la tarea de decifrar el lenguaje de los sumerios (el _cuneiforme_). Hace un par de años se encontraron más tabletas con escritos de un lenguaje extraño, parecido al _cuneiforme_ pero un tanto más complejo en apariencia. Un reconocidísimo grupo arqueológico de la UNAM conocido como los _topotlatchcos_ se encargó de tomar muestras en la ahora fragmentada mesopotamia para intentar entender este lenguaje y ayudar a rescatar este conocimiento cuya ausencia nos quita el sueño.\n",
    "\n",
    "Sin embargo, todos estos datos que han recolectado no se van a limpiar ni organizar solos. Es necesario un poderoso equipo de analistas que ayuden a ponerle pies y cabeza a esta información, y eso es lo que harán ustedes. Comenzamos, como típicamente lo hemos hecho en el curso, por cargar las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Ya saben, graficas chulas\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a ponernos a cargar los datos: para esta primera sección hay un total de 4 archivos, todos dentro del folder 'datos_exp_mesop', llamados Iraq.txt, Syria.txt, ArabiaSaudita.txt y Turquia.txt. Cada archivo tiene registros de lo que se cree son la prueba del pase de conocimiento de los Anunnaki a los Sumerios, reportados por cada una de las subdivisiones de los _topotlatchcos_ asignada a cada región. La descripción de las columnas es la siguiente:\n",
    "\n",
    "* `Tableta`: Un identificador de la tableta registrada\n",
    "* `NumLineasV`: Número de líneas verticales en el pictograma/caracter\n",
    "* `NumLineasH`: Número de líneas horizontales en el pictograma/caracter\n",
    "* `NumLineasD`: Número de líneas diagonales en el pictograma/caracter\n",
    "* `NumCirc`: Número de círculos en el pictograma/caracter.\n",
    "* `Profundidad`: La profundidad promedio del caracter\n",
    "* `Ancho`: El ancho promedio de las líneas en el caracter\n",
    "* `Rugosidad`: La rugosidad del trazo.\n",
    "\n",
    "Como primer tarea, generen el archivo `annk.txt` que contenga la información de los 4 archivos originales. Lo pueden hacer desde la terminal, o con Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('annk.txt') # Fallará, porque el archivo no existe.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 0\n",
    "\n",
    "Calcule cuál es la cantidad promedio de caracteres por tableta encontrada. También calcule la desviación estandar de este número.\n",
    "\n",
    "__Hint__: Use la función `.value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1\n",
    "Encuentre el número de combinaciones únicas de los valores de las columnas `NumLineasV`, `NumLineasH`, `NumLineasD` y `NumCirc`. Para ello, puede hacer un uso inteligente del método `.drop_duplicates()` de los dataframe de pandas (si no lo entienden, busquen en internet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2\n",
    "Ahora, hay que añadir una columna llamada \"Id\", en donde vamos a colocar el identificador para cada combinación de caracteres; es decir, la primer combinación será reconocida por \"1\", la segunda por \"2\" y así.\n",
    "\n",
    "__Hint__: Construyan un diccionario que haga un mapeo de una cadena de caracteres (la combinación de las 4 columnas que definen al caracter) a un entero (el identificador).\n",
    "\n",
    "Usarán el método `apply` en el dataframe con las combinaciones únicas. Como última pista, si ustedes hacen `str(df.loc[0][vc].values)` van a obtener una cadena de caracteres única a esa combinación (por ejemplo, `'[3 0 0 0]'`). Usen esto para sacarle provecho al \"apply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3\n",
    "Se sabe que en la escritura de los Anunnaki no sólo importan los símbolos dibujados, también hay algunas características físicas que proporcionan información al lector. Para ello están las últimas 3 columnas del dataframe, `Profundidad` (medida en milímetros), `Ancho` (medida en milímetros) y `Rugosidad` (medida en micrómetros). Con ayuda de estas 3 columnas deberán tener ustedes el poder de identificar cuántos grupos distintos de caracteres hay: Es decir, los Anunnaki tenían grupos de caracteres dentro de su escritura determinados por las tres variables físicas antes mencionadas. Para su conveniencia está aquí una clase que hace el método de K-Means, al cuál le falta sólo una pieza: la misma función/lambda que hicieron en clase, señalada con muchos signos de número:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, data, centroids = None):\n",
    "        self.data = data\n",
    "        self.centroids = centroids\n",
    "        #Rellene la siguiente lambda para calcular el índice del centroide que más cerca esté a un renglón\n",
    "        ###################################################################################################\n",
    "        self.closest = \n",
    "        ###################################################################################################\n",
    "        \n",
    "    def run(self,k = 2):\n",
    "        \"\"\"Calculates the k centroids to divide the data, using k-means++ as initial points\"\"\"\n",
    "        #El siguiente argumento hace una matriz de \"Rangos\"\n",
    "        ranges = np.concatenate( (np.matrix(self.data.min().values),np.matrix(self.data.max().values)) ).T\n",
    "        self.centroids = self.kmeanspp_init(ranges, k)\n",
    "        \n",
    "        changed = True;\n",
    "        labels = None\n",
    "        counter = 0\n",
    "        while changed and counter < 8:\n",
    "            oldLabels = labels\n",
    "            labels = self.data.apply(self.closest, axis = 1)\n",
    "\n",
    "            for i in range(0, k):\n",
    "                if (labels==i).any():\n",
    "                    self.centroids[i,:] = (self.data[labels==i].sum().values)/np.sum(labels==i)\n",
    "\n",
    "            changed = oldLabels != labels\n",
    "            changed = changed.any()\n",
    "            counter = counter+1\n",
    "        return self.centroids, labels\n",
    "    \n",
    "    def predict(self, newData):\n",
    "        result = newData.copy()\n",
    "        return result.apply(self.closest, axis = 1)\n",
    "        \n",
    "    def random_init(self, ranges, k):\n",
    "        #Con ella, se hace un vector aleatorio de las dimensiones de cada renglón de nuestros datos\n",
    "        rVec = np.matrix(np.random.random(ranges.shape[0])).T\n",
    "        #Se añade un centroide\n",
    "        centroids = (np.multiply(ranges[:,1]-ranges[:,0],rVec) + ranges[:,0]).T\n",
    "        #Se añaden el resto de los centroides\n",
    "        for i in range(1,k):\n",
    "            rVec = np.matrix(np.random.random(ranges.shape[0])).T\n",
    "            centroids = np.concatenate((centroids,(np.multiply(ranges[:,1]-ranges[:,0],rVec) + ranges[:,0]).T))\n",
    "        return centroids\n",
    "    \n",
    "    def kmeanspp_init(self, ranges, k):\n",
    "        #Con ella, se hace un vector aleatorio de las dimensiones de cada renglón de nuestros datos\n",
    "        rVec = np.matrix(np.random.random(ranges.shape[0])).T\n",
    "        #Se añade un centroide\n",
    "        centroids = (np.multiply(ranges[:,1]-ranges[:,0],rVec) + ranges[:,0]).T\n",
    "        #Se añaden el resto de los centroides\n",
    "        for i in range(1,k):\n",
    "            computeDistance = lambda row: np.min(np.sum(np.square(centroids - np.matrix(row)), axis = 1))\n",
    "            distances = self.data.apply(computeDistance, axis = 1)\n",
    "            cumprobs = distances / distances.sum()\n",
    "            cumprobs = cumprobs.cumsum()\n",
    "            r = np.random.random()\n",
    "            ind = np.where( cumprobs >= r)[0][0] #First element of list in tupple\n",
    "            centroids = np.concatenate((centroids,np.matrix(self.data.iloc[ind])))\n",
    "        return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hayan rellenado esa línea, tienen ya una clase que puede hacer el algoritmo de K-Means con un comienzo inteligente conocido como _k-means++_ (da una convergencia más rápida). Además de eso, tenga usted la función _codito_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codito(data, ki = 2, kf = 9):\n",
    "    \"\"\"Calcula el puntaje para las k entre ki y kf\"\"\"\n",
    "    costs = pd.DataFrame(columns = [\"K\", \"Score\"])\n",
    "    centroids = []\n",
    "    labels = []\n",
    "    km = KMeans(data)\n",
    "    for k in range(ki,kf+1):\n",
    "        lowestCost = None\n",
    "        lowestC = None\n",
    "        for j in range(0,4):\n",
    "            c,l = km.run(k)\n",
    "            tmpdf = data.copy()\n",
    "            tmpdf[\"Label\"] = l\n",
    "            currentCost = np.sum(\n",
    "                tmpdf.apply(lambda row: np.sum(np.square(np.matrix(row[cl]) - c[int(row[\"Label\"]), :])), axis = 1)\n",
    "            )\n",
    "            lowestC = c if lowestC is None or lowestCost > currentCost else lowestC\n",
    "            lowestCost = currentCost if lowestCost is None or lowestCost > currentCost else lowestCost\n",
    "        costs.loc[costs.shape[0]] = [k, lowestCost]\n",
    "        centroids.append(lowestC)\n",
    "        print(\"Para k = \" + str(k)+ \", puntaje: \" + str(costs.iloc[costs.shape[0]-1].Score))\n",
    "    return costs, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función ejecuta K-Means para distintas k's y les asigna un \"score\" (en este caso, la suma de las distancias al cuadrado de cada punto al centroide más cercano). Como fue discutido en clase, estos datos se verán como un codito, y el punto de inflexión es la k óptima.\n",
    "\n",
    "Van a necesitar esto porque __no se sabe__ en cuántos grupos dividían sus caracteres los Annunaki.\n",
    "\n",
    "Ejecute la función codito, y enuentre la k óptima. Note que el argumento de la función codito es un dataframe pero que sólo contiene las columnas en donde se ejecutará k-Means (utilice la lista `cl` otorgada abajo)\n",
    "\n",
    "__Hint__: **NO EJECUTEN EL ALGORITMO NI EL CODITO CON TODOS LOS DATOS**. K-Means es costoso (en tiempo), y ustedes lo tienen muy limitado. En lugar de eso, hagan un nuevo dataframe pequeño (de unos 2000 renglones) que tenga un \"muestreo\" del dataframe original: es decir, tomen de manera __uniformemente aleatoria__ 2000 renglones del dataframe original, y usen este dataframe para encontrar la k-óptima.\n",
    "\n",
    "__Hint 2__: Pueden generar 2000 índices únicos entre 0 y 50,000 así: `random.sample(range(0, 50000), 2000)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4\n",
    "\n",
    "De los grupos que haya encontrado en la parte anterior, conteste lo siguiente:\n",
    "\n",
    "* Cuántos grupos tienen caracteres que NO están compartidos con otros grupos?\n",
    "* Cuántos grupos tienen caracteres que SÍ están compartidos con otros grupos?\n",
    "\n",
    "__Hint__: la estructura de datos `set` de python es de gloriosa ayuda: Ustedes pueden añadir todos los \"id\" a un set por cada grupo, para ver qué id's están contenidos en cada grupo. Con el operador de comparación (==) ya tienen la respuesta. Incluso existe la función `isdisjoint` (ejemplo: set([0,1]).isdisjoint(set([1,2])) regresará falso pues los sets comparten el 1).\n",
    "\n",
    "Métodos que pueden ser útiles\n",
    "* `.groupby('Label')['Id'].unique().tolist()` (pandas, hace un df con los indices únicos pertenecientes a cada label)\n",
    "* `.groupby('Label').size()` (pandas, número de elementos en cada \"grupo\" denominado por \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí va el código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 5\n",
    "\n",
    "Hemos recibido una buena nueva del equipo: Los grupos de caracteres que comparten caracteres son la escritura principal, son letras vaya. Así que podemos \"considerarlos\" lo mismo.\n",
    "\n",
    "Haga un nuevo dataframe donde estén todos los caracteres que son de grupos no disjuntos.\n",
    "\n",
    "__Hint__: Con la lista creada anteriormente, pueden usar `.apply` y una lambda que verifique si el campo `Label` de cada renglón está en la lista, algo como `row.Label in jointsets` basta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí va el código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 6\n",
    "\n",
    "Se sabe que los universitarios que mandamos a hacer la exploración son fanáticos del alcohol, así que es probable que haya valores atípicos, es decir, caracteres que ocurren sólo un par de veces. Puede considerar por ejemplo la letra de menor frecuencia [en el inglés](https://en.wikipedia.org/wiki/Letter_frequency), en el [español](https://es.wikipedia.org/wiki/Frecuencia_de_aparici%C3%B3n_de_letras), o en [todos estos otros idiomas](https://en.wikipedia.org/wiki/Letter_frequency#Relative_frequencies_of_letters_in_other_languages). Grafique las frecuencias de cada una de estas letras únicas, descarte aquéllas que no sea probable que sean una letra, y calcule nuevamente el número de letras.\n",
    "\n",
    "__Hint__: el método `.value_counts()` de pandas (que funciona sobre una columna del df, sobre una serie vaya) se encarga de contar cuántas veces se repite un elemento. Use este método para después, calcular una serie con el porcentaje de veces que aparece cada caracter. Para graficar el histograma, utilice la función `.plot(kind = \"bar\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí el código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 7 (opcional)\n",
    "Dadas las frecuencias que hay en el último histograma, adivine la respuesta a las siguientes preguntas:\n",
    "\n",
    "* De los k grupos que encontró, el de menor cardinalidad tiene una estructura muy curiosa. Vea los identificadores que lo componen, y vea qué geometría compone los caracteres (lineas horizontales, verticales, diagonales y círculos). Qué es lo que contiene este grupo?\n",
    "\n",
    "* Viendo la distribución de frecuencias de los grupos no disjuntos, y viendo [estas tablas](https://en.wikipedia.org/wiki/Letter_frequency#Relative_frequencies_of_letters_in_other_languages), conteste: Qué idioma hablaban los Anunnaki que se sigue usando hoy en día?\n",
    "\n",
    "* Si ya sabe qué idioma es, adivine qué simbolizan los grupos que componen el alfabeto (los que resultaron de los k promedios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí la solución"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
